{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f79bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/guess_age_gender.wav\n",
    "# !wget https://huggingface.co/datasets/mesolitica/malaysian-youtube-audio-instructions/resolve/main/mixtral-audio-instruction.jsonl\n",
    "# !wget https://huggingface.co/datasets/mesolitica/Malaysian-SFT/resolve/main/combine/combined-malaysian-sft-20k-sample.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62834cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/home/husein/ssd3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d665f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/mesolitica/malaysian-dataset/refs/heads/master/llm-instruction/malaysian-sft/malaysian_sft.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7643236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datasets import Audio\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoProcessor, Qwen2AudioForConditionalGeneration, AutoConfig, AutoModelForCausalLM\n",
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "from malaysian_sft import accept\n",
    "import streaming\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "    'position_ids': 'uint32',\n",
    "    'attention_mask': 'uint32',\n",
    "    'audio': 'str',\n",
    "    'text': 'str'\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff78d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_class = Audio(sampling_rate=16000)\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "tokenizer = processor.tokenizer\n",
    "audio_token = \"<|AUDIO|>\"\n",
    "audio_bos_token = \"<|audio_bos|>\"\n",
    "audio_eos_token = \"<|audio_eos|>\"\n",
    "audio_token_id = processor.tokenizer._convert_token_to_id_with_added_voc('<|AUDIO|>')\n",
    "pad_token_id = processor.tokenizer.pad_token_id\n",
    "torch_dtype = torch.bfloat16\n",
    "min_dtype = torch.finfo(torch_dtype).min\n",
    "sequence_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8806d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.feature_extractor.hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03dfc9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# df = pd.read_parquet('sample_filtered_gpt_omni-00000-of-00001.parquet')\n",
    "# for i in tqdm(range(len(df))):\n",
    "#     conversation = [\n",
    "#         {\"role\": \"system\", \"content\": df.iloc[i]['system']},\n",
    "#         {\"role\": \"user\", \"content\": [\n",
    "#             {\"type\": \"audio\", \"audio_url\": df.iloc[i]['sliced_audio_filename']},\n",
    "#         ]},\n",
    "#         {\"role\": \"assistant\", \"content\": df.iloc[i]['answer']},\n",
    "#     ]\n",
    "#     text = processor.apply_chat_template(conversation, tokenize=False)\n",
    "#     data.append({\n",
    "#         'text': text,\n",
    "#         'audio': df.iloc[i]['sliced_audio_filename'],\n",
    "#     })\n",
    "    \n",
    "# df = pd.read_parquet('random_question_chunks-00000-of-00001.parquet')\n",
    "# for i in tqdm(range(len(df))):\n",
    "#     conversation = [\n",
    "#         {\"role\": \"system\", \"content\": df.iloc[i]['system']},\n",
    "#         {\"role\": \"user\", \"content\": [\n",
    "#             {\"type\": \"audio\", \"audio_url\": df.iloc[i]['sliced_audio_filename']},\n",
    "#         ]},\n",
    "#         {\"role\": \"assistant\", \"content\": df.iloc[i]['answer']},\n",
    "#     ]\n",
    "#     text = processor.apply_chat_template(conversation, tokenize=False)\n",
    "#     data.append({\n",
    "#         'text': text,\n",
    "#         'audio': df.iloc[i]['sliced_audio_filename'],\n",
    "#     })\n",
    "\n",
    "# with open('prepare-mixtral-audio-instruction.json') as fopen:\n",
    "#     mixtral = json.load(fopen)\n",
    "    \n",
    "# for row in tqdm(mixtral):\n",
    "#     conversation = [\n",
    "#         {\"role\": \"system\", \"content\": row['system']},\n",
    "#         {\"role\": \"user\", \"content\": [\n",
    "#             {\"type\": \"audio\", \"audio_url\": row['audio']},\n",
    "#             {\"type\": \"text\", \"text\": row['question']},\n",
    "#         ]},\n",
    "#         {\"role\": \"assistant\", \"content\": row['answer']},\n",
    "#     ]\n",
    "#     text = processor.apply_chat_template(conversation, tokenize=False)\n",
    "#     data.append({\n",
    "#         'text': text,\n",
    "#         'audio': row['audio'],\n",
    "#     })\n",
    "\n",
    "# with open('processed.json', 'w') as fopen:\n",
    "#     json.dump(data, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac749cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed.json') as fopen:\n",
    "    data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86fb805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "def collator(batch, batch_position_ids, audio):\n",
    "    input_ids = []\n",
    "    position_ids = []\n",
    "    masks = []\n",
    "    for i in range(len(batch)):\n",
    "        l = len(batch[i])\n",
    "        input_ids.extend(batch[i])\n",
    "        position_ids.extend(batch_position_ids[i])\n",
    "        masks.append(l)\n",
    "        \n",
    "    input_ids = input_ids + [pad_token_id] * (sequence_length - len(input_ids))\n",
    "    position_ids = position_ids + [0] * (sequence_length - len(position_ids))\n",
    "    \n",
    "    return {\n",
    "        'input_ids': np.array(input_ids).astype(np.uint32),\n",
    "        'position_ids': np.array(position_ids).astype(np.uint32),\n",
    "        'attention_mask': np.array(masks).astype(np.uint32),\n",
    "        'audio': json.dumps(audio),\n",
    "        'text': '',\n",
    "    }\n",
    "\n",
    "def get_new_token(f, sample):\n",
    "\n",
    "    audio_ = audio_class.decode_example(audio_class.encode_example(f))['array']\n",
    "\n",
    "#     inputs_audio = processor.feature_extractor(\n",
    "#         [audio_], \n",
    "#         return_attention_mask=True, \n",
    "#         padding=\"max_length\", \n",
    "#         sampling_rate=16000,\n",
    "#         return_tensors = 'pt'\n",
    "#     )\n",
    "\n",
    "    audio_lengths = [min(3000, math.ceil(len(audio_) / processor.feature_extractor.hop_length))]\n",
    "\n",
    "    num_audio_tokens = sample.count(audio_token)\n",
    "    replace_str = []\n",
    "    while audio_token in sample:\n",
    "        audio_length = audio_lengths.pop(0)\n",
    "        input_length = (audio_length - 1) // 2 + 1\n",
    "        num_audio_tokens = (input_length - 2) // 2 + 1\n",
    "\n",
    "        expanded_audio_token = audio_token * num_audio_tokens\n",
    "\n",
    "        audio_token_start_idx = sample.find(audio_token)\n",
    "        audio_token_end_idx = audio_token_start_idx + len(audio_token)\n",
    "\n",
    "        has_bos = (\n",
    "            sample[audio_token_start_idx - len(audio_bos_token) : audio_token_start_idx]\n",
    "            == audio_bos_token\n",
    "        )\n",
    "        has_eos = (\n",
    "            sample[audio_token_end_idx : audio_token_end_idx + len(audio_eos_token)]\n",
    "            == audio_eos_token\n",
    "        )\n",
    "\n",
    "        if not has_bos and not has_eos:\n",
    "            expanded_audio_token = audio_bos_token + expanded_audio_token + audio_eos_token\n",
    "\n",
    "        replace_str.append(expanded_audio_token)\n",
    "        sample = sample.replace(audio_token, \"<placeholder>\", 1)\n",
    "\n",
    "    while \"<placeholder>\" in sample:\n",
    "        sample = sample.replace(\"<placeholder>\", replace_str.pop(0), 1)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c242bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm -rf tokenized-audio-4096\n",
    "!mkdir tokenized-audio-4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c08e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def loop(files, block_size = sequence_length):\n",
    "    rows, index = files\n",
    "    out_root = f'tokenized-audio-4096/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    count = 0\n",
    "    temp = []\n",
    "    position_ids = []\n",
    "    audio = []\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=None, hashes=hashes) as out:\n",
    "        for row in tqdm(rows, desc=f'loop {index}'):\n",
    "            prompt = get_new_token(row['audio'], row['text'])\n",
    "            outputs = tokenizer(prompt, add_special_tokens = False)\n",
    "            length = len(outputs['input_ids'])\n",
    "            if length > block_size:\n",
    "                continue\n",
    "            \n",
    "            if count + length > block_size:\n",
    "                o = collator(temp, position_ids, audio)\n",
    "                out.write(o)\n",
    "                temp = [outputs['input_ids']]\n",
    "                position_ids = [range(len(outputs['input_ids']))]\n",
    "                audio = [row['audio']]\n",
    "                count = length\n",
    "            \n",
    "            else:\n",
    "                temp.append(outputs['input_ids'])\n",
    "                position_ids.append(range(len(outputs['input_ids'])))\n",
    "                audio.append(row['audio'])\n",
    "                count += length\n",
    "        \n",
    "        if len(temp):\n",
    "            o = collator(temp, position_ids, audio)\n",
    "            out.write(o)\n",
    "    return [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a56643c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop((data, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ee2f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop 9:   4%|██▊                                                                         | 726/20000 [00:08<03:11, 100.65it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10176 > 8192). Running this sequence through the model will result in indexing errors\n",
      "loop 8:  38%|████████████████████████████▌                                              | 7612/20000 [00:40<00:58, 211.59it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (10240 > 8192). Running this sequence through the model will result in indexing errors\n",
      "loop 6: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [01:40<00:00, 198.61it/s]\n",
      "loop 5: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [01:40<00:00, 198.06it/s]\n",
      "loop 7: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [01:40<00:00, 198.77it/s]\n",
      "loop 8: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [01:59<00:00, 166.71it/s]\n",
      "loop 0: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [02:02<00:00, 162.75it/s]\n",
      "loop 3: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [02:03<00:00, 162.39it/s]\n",
      "loop 4: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [02:03<00:00, 162.30it/s]\n",
      "loop 1: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [02:04<00:00, 160.97it/s]\n",
      "loop 2: 100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [02:04<00:00, 160.59it/s]\n",
      "loop 9: 100%|███████████████████████████████████████████████████████████████████████████| 20000/20000 [03:25<00:00, 97.48it/s]\n",
      "loop 17: 100%|█████████████████████████████████████████████████████████████████████████| 16331/16331 [02:41<00:00, 100.88it/s]\n",
      "loop 11: 100%|█████████████████████████████████████████████████████████████████████████| 20000/20000 [03:16<00:00, 101.86it/s]\n",
      "loop 12: 100%|█████████████████████████████████████████████████████████████████████████| 20000/20000 [03:16<00:00, 101.75it/s]\n",
      "loop 10: 100%|█████████████████████████████████████████████████████████████████████████| 20000/20000 [03:17<00:00, 101.48it/s]\n",
      "loop 13: 100%|█████████████████████████████████████████████████████████████████████████| 20000/20000 [03:11<00:00, 104.20it/s]\n",
      "loop 15: 100%|█████████████████████████████████████████████████████████████████████████| 20000/20000 [03:11<00:00, 104.20it/s]\n",
      "loop 16: 100%|█████████████████████████████████████████████████████████████████████████| 20000/20000 [03:11<00:00, 104.34it/s]\n",
      "loop 14: 100%|█████████████████████████████████████████████████████████████████████████| 20000/20000 [03:14<00:00, 102.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from multiprocess import Pool\n",
    "import mp\n",
    "\n",
    "chunks = mp.chunks(data, 20000)\n",
    "pool = Pool(10)\n",
    "pooled = pool.map(loop, chunks)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f580cac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = glob('tokenized-audio-4096/tokenized-*') + glob('tokenized-4k/tokenized-*')\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c61e275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf packing-4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1040fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6527/6527 [00:00<00:00, 13453.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6445/6445 [00:00<00:00, 12821.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5199/5199 [00:00<00:00, 15520.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6440/6440 [00:00<00:00, 11385.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1429/1429 [00:00<00:00, 43104.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1580/1580 [00:00<00:00, 11197.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1266/1266 [00:00<00:00, 9407.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6434/6434 [00:00<00:00, 14285.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6390/6390 [00:00<00:00, 13549.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2791/2791 [00:00<00:00, 16395.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1996/1996 [00:00<00:00, 13583.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1268/1268 [00:00<00:00, 9848.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6461/6461 [00:00<00:00, 14559.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6541/6541 [00:00<00:00, 14707.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1985/1985 [00:00<00:00, 13839.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6394/6394 [00:00<00:00, 11998.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 14020.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1588/1588 [00:00<00:00, 43054.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8899/8899 [00:00<00:00, 9218.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 10288/10288 [00:00<00:00, 10497.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3630/3630 [00:00<00:00, 13403.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6090/6090 [00:00<00:00, 9454.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7390/7390 [00:00<00:00, 9546.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4046/4046 [00:00<00:00, 9924.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5253/5253 [00:00<00:00, 10376.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12469/12469 [00:01<00:00, 9373.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 10850/10850 [00:01<00:00, 10005.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8371/8371 [00:00<00:00, 9418.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1402/1402 [00:00<00:00, 8297.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 15367/15367 [00:01<00:00, 10729.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 15427/15427 [00:01<00:00, 9462.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13322/13322 [00:01<00:00, 8855.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1396/1396 [00:00<00:00, 4153.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 9205/9205 [00:02<00:00, 4166.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2078/2078 [00:00<00:00, 10250.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 18664/18664 [00:01<00:00, 9778.53it/s]\n"
     ]
    }
   ],
   "source": [
    "with MDSWriter(out='packing-4k', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    for f in folders:\n",
    "        try:\n",
    "            dataset = LocalDataset(local=f)\n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                out.write(dataset[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "817e6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def block_diagonal_concat_inverted(*masks, dtype=torch.bfloat16):\n",
    "    total_size = sum(mask.size(0) for mask in masks)\n",
    "    combined_mask = torch.zeros(total_size, total_size, dtype=dtype)\n",
    "\n",
    "    current_pos = 0\n",
    "\n",
    "    for mask in masks:\n",
    "        size = mask.size(0)\n",
    "        combined_mask[current_pos:current_pos + size, current_pos:current_pos + size] = mask\n",
    "        current_pos += size\n",
    "\n",
    "    min_value = torch.finfo(dtype).min if dtype.is_floating_point else torch.iinfo(dtype).min\n",
    "    inverted_mask = torch.where(combined_mask == 1, torch.tensor(0, dtype=dtype), min_value)\n",
    "    return inverted_mask.unsqueeze(0)\n",
    "\n",
    "def pad_attention_mask_4d(attention_mask, max_size = 4096):\n",
    "    maxlen_right = max_size\n",
    "    maxlen_bottom = max_size\n",
    "    attention_mask = [\n",
    "        F.pad(\n",
    "            attention_mask[i],\n",
    "            (0, maxlen_right - attention_mask[i].shape[-2], 0, maxlen_bottom - attention_mask[i].shape[-1])) for i in range(\n",
    "            len(attention_mask))]\n",
    "    return torch.stack(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64735415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(batch):\n",
    "    batch = [b for b in batch if b is not None] \n",
    "    input_ids, attention_mask, position_ids, labels = [], [], [], []\n",
    "    input_features, feature_attention_mask = [], []\n",
    "\n",
    "    for b in batch:\n",
    "        if 'input_features' in b:\n",
    "            input_features.append(b['input_features'])\n",
    "            feature_attention_mask.append(b['feature_attention_mask'])\n",
    "        input_ids.append(b['input_ids'][None])\n",
    "        attention_mask.append(b['attention_mask'])\n",
    "        position_ids.append(b['position_ids'][None])\n",
    "        labels.append(b['labels'][None])\n",
    "\n",
    "    input_ids = {\n",
    "        'input_ids': torch.concat(input_ids, 0),\n",
    "        'attention_mask': pad_attention_mask_4d(attention_mask, sequence_length),\n",
    "        'position_ids': torch.concat(position_ids, 0),\n",
    "        'labels': torch.concat(labels, 0),\n",
    "    }\n",
    "    if len(input_features):\n",
    "        input_ids['input_features'] = torch.concat(input_features, 0)\n",
    "        input_ids['feature_attention_mask'] = torch.concat(feature_attention_mask, 0)\n",
    "\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "588721cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFixed(torch.utils.data.Dataset):\n",
    "    def __init__(self, local):\n",
    "        self.dataset = LocalDataset(local=local)\n",
    "        self.audio = Audio(sampling_rate=16000)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        try:\n",
    "            data.pop('text', None)\n",
    "            audio_files = data.pop('audio', '')\n",
    "            data['labels'] = data[\"input_ids\"].copy()\n",
    "            masking = data.pop('attention_mask')\n",
    "\n",
    "            data.pop('token_type_ids', None)\n",
    "            for k in data.keys():\n",
    "                data[k] = torch.tensor(data[k].astype(np.int64))\n",
    "\n",
    "            masks = []\n",
    "            for m in masking:\n",
    "                masks.append(torch.tril(torch.ones(m, m)))\n",
    "            attention_mask = block_diagonal_concat_inverted(*masks)\n",
    "            data['attention_mask'] = attention_mask\n",
    "\n",
    "            data['labels'][data['labels'] == audio_token_id] = -100\n",
    "            data['labels'][data['labels'] == pad_token_id] = -100\n",
    "\n",
    "            if len(audio_files):\n",
    "                files = json.loads(audio_files)\n",
    "                print(files)\n",
    "                audios = []\n",
    "                for f in files:\n",
    "                    audio = self.audio.decode_example(\n",
    "                    self.audio.encode_example(f))['array']\n",
    "                    audios.append(audio)\n",
    "\n",
    "                inputs_audio = processor.feature_extractor(\n",
    "                    audios, return_attention_mask=True, \n",
    "                    sampling_rate=16000,\n",
    "                    padding=\"max_length\", return_tensors = 'pt')\n",
    "\n",
    "                data['input_features'] = inputs_audio['input_features']\n",
    "                data['feature_attention_mask'] = inputs_audio['attention_mask']\n",
    "                \n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Exception', e)\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc76f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetFixed('packing-4k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "091f93d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filter-audio/3-3061-34.mp3', 'filter-audio/3-3061-34.mp3']\n"
     ]
    }
   ],
   "source": [
    "batch = [dataset[0], dataset[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e782a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = collator(batch)\n",
    "b['feature_attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90b9e61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['feature_attention_mask'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c689e8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3000 - 1) // 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01461d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0G\tpacking-4k\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs packing-4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6f60f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a7330abd0946d5af101004498e9f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00069.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee92f4f5756a406b97349f247a5d734c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00067.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a528e1c03167419592daf65db636aa85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00062.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c419e6bbfa54b0d946c66169f359929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00061.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcede3dd24c46b0b1902bd7cb54218c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00068.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa69488da7e94d5c96f364989fbe28dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 47 LFS files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96e09c422a8448eb2c6a7b1fbd96214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00070.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d113f0449964fb8a7d6bd2007d15fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00071.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea626ab8fe74e348843b650a8f23011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00072.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae9476272a9447383575a5943f5e5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00073.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dee825f5a74a6a9db4a749dd245f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00074.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf94c17aca8640ecb993c802a3b1bc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00075.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f60317b84f4bb5a34c04a0c2d79dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00076.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fab9ae5a764c149161cb99868dc708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00077.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ceab72940c947e49149e6f881530ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00078.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dee919a1872450d961733e966c23a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00079.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa7d9bf4d31477a98c6ddfd3d2cd2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00080.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3e6b9f78ec4e7f9216eef5efa35e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00081.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef7c06b12c24662a9986952bbe0f953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00082.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d1ed1e8586411da1de237634157efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00083.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323acc6d13cb4429a7d0fd6e5af91667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00084.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e841862b09f64420af08931abfd542f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00085.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6198fbc308ed48ed97abd8063e0934dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00086.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ece8d855688404fb9b4720af81bc7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00087.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd724b3be6c04ab28e65720435b124f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00088.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cb2ba649b5446fb5d16a3c12dbf7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00089.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179199b20f9b48ed8c8b2c1446ba03e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00090.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bfa84d48db48fcbb140a7ec33bddaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00091.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fe91cb5193415a9edcc5cce616b335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00092.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f896afe1ad5497da7ecb93b8abe82df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00093.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2477afb95f944e898506e9565aaef102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00094.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d9473ea99840f7829363dd3da5db99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00095.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2297952e80db4e8aa68dfcb875cea679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00096.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046c38f6536747ab9a503491e9d0d6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00097.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982ac66f55cc4d63a573e5b4cc2ee0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00098.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddf1b0049354215b62d878ef5a39202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00099.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d186089be6b8427684b1a123d91bc813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00100.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9862c85e8b43d38a4693112b4d8d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00101.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276a7d0b30e5419180813c6905460b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00102.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e90455967444a984b4f469803d5b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00103.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870e0991563a4f108259e5cd10e741b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00104.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae8e96499814c90aab716a4fe0b8e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00105.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f1f22d8a0843e18b5c781687232d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00106.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5ade12d9d04cde8e28dd067149e19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00107.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d860ffbe92a548f69945d21544c80a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00108.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650ac9e08a364a31be4d6ec2ff855574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00109.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c1a84311f24d58a10bdafc55f21cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00110.mds:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecb11b38acf4b329937f41cb1344987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "shard.00111.mds:   0%|          | 0.00/14.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/huseinzol05/malaysian-audio-qa-pretraining/commit/3cf23fc9b84f4366714556f43f40789f56b96541', commit_message='Upload folder using huggingface_hub', commit_description='', oid='3cf23fc9b84f4366714556f43f40789f56b96541', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/huseinzol05/malaysian-audio-qa-pretraining', endpoint='https://huggingface.co', repo_type='dataset', repo_id='huseinzol05/malaysian-audio-qa-pretraining'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=\"packing-4k\",\n",
    "    repo_id=\"huseinzol05/malaysian-audio-qa-pretraining\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
