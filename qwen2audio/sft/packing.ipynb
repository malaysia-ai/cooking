{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540c66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/guess_age_gender.wav\n",
    "# !wget https://huggingface.co/datasets/mesolitica/Malaysian-SFT/resolve/main/combine/combined-malaysian-sft-20k-sample.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4d5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/home/husein/ssd3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e0eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datasets import Audio\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoProcessor, Qwen2AudioForConditionalGeneration, AutoConfig, AutoModelForCausalLM\n",
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "import streaming\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "    'position_ids': 'uint32',\n",
    "    'attention_mask': 'uint32',\n",
    "    'audio': 'str',\n",
    "    'text': 'str'\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10174eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "audio_token = \"<|AUDIO|>\"\n",
    "audio_bos_token = \"<|audio_bos|>\"\n",
    "audio_eos_token = \"<|audio_eos|>\"\n",
    "audio_token_id = processor.tokenizer._convert_token_to_id_with_added_voc('<|AUDIO|>')\n",
    "pad_token_id = processor.tokenizer.pad_token_id\n",
    "tokenizer = processor.tokenizer\n",
    "torch_dtype = torch.bfloat16\n",
    "min_dtype = torch.finfo(torch_dtype).min\n",
    "sequence_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378f0891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine = []\n",
    "with open('combined-malaysian-sft-20k-sample.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        combine.append(l)\n",
    "        if len(combine) > 100:\n",
    "            break\n",
    "\n",
    "len(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7eeedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def collator(batch, batch_position_ids):\n",
    "    input_ids = []\n",
    "    position_ids = []\n",
    "    masks = []\n",
    "    for i in range(len(batch)):\n",
    "        l = len(batch[i])\n",
    "        input_ids.extend(batch[i])\n",
    "        position_ids.extend(batch_position_ids[i])\n",
    "        masks.append(l)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': np.array(input_ids).astype(np.uint32),\n",
    "        'position_ids': np.array(position_ids).astype(np.uint32),\n",
    "        'attention_mask': np.array(masks).astype(np.uint32),\n",
    "        'audio': '',\n",
    "        'text': '',\n",
    "    }\n",
    "\n",
    "def slice_and_balance(nested_list, size):\n",
    "    first = []\n",
    "    balance = []\n",
    "    current_size = 0\n",
    "\n",
    "    for sublist in nested_list:\n",
    "        if current_size < size:\n",
    "            remaining_space = size - current_size\n",
    "            if len(sublist) <= remaining_space:\n",
    "                first.append(sublist)\n",
    "                current_size += len(sublist)\n",
    "            else:\n",
    "                first.append(sublist[:remaining_space])\n",
    "                balance.append(sublist[remaining_space:])\n",
    "                current_size = size\n",
    "        else:\n",
    "            balance.append(sublist)\n",
    "    \n",
    "    return first, balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228fbb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tokenized-4k’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir tokenized-4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffea639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def loop(files, block_size = sequence_length):\n",
    "    rows, index = files\n",
    "    out_root = f'tokenized-4k/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    count = 0\n",
    "    temp = []\n",
    "    position_ids = []\n",
    "    last_block, last_position_block = None, None\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=None, hashes=hashes) as out:\n",
    "        for row in tqdm(rows):\n",
    "            prompt = tokenizer.apply_chat_template(row, tokenize=False)\n",
    "            outputs = tokenizer(prompt, add_special_tokens = False)\n",
    "            temp.append(outputs['input_ids'])\n",
    "            position_ids.append(range(len(outputs['input_ids'])))\n",
    "            count += len(outputs['input_ids'])\n",
    "            while count >= block_size:\n",
    "                block, temp = slice_and_balance(temp, block_size)\n",
    "                block_position, position_ids = slice_and_balance(position_ids, block_size)\n",
    "                count = count - block_size\n",
    "                o = collator(block, block_position)\n",
    "                last_block = block\n",
    "                last_position_block = block_position\n",
    "                out.write(o)\n",
    "                \n",
    "        block, _ = slice_and_balance(last_block, block_size - count)\n",
    "        block_position, _ = slice_and_balance(last_position_block, block_size - count)\n",
    "\n",
    "        block.extend(temp)\n",
    "        block_position.extend(position_ids)\n",
    "\n",
    "        o = collator(block, block_position)\n",
    "        if len(o['input_ids']) == block_size:\n",
    "            out.write(o)\n",
    "            return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0c9a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1072.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([  8656,  11814,   9810,   3362,    276,    452,  86415,   1728,\n",
       "         10371,  49935,    272,   1225,    391,   9101,  58554,     74,\n",
       "          6053,     11,  92619,  67431,  97934,    276,   2953,    709,\n",
       "            74,   2154,  78549,  10215,   1346,   1574,     75,  43518,\n",
       "         10582,   1330,   1579,   9101,  14885,  52067,  50977,    278,\n",
       "         22051,    382,    818,   2267,    595,  12800,    355,    452,\n",
       "         86415,   1728,    595,  27574,    372,    293,   9247,  78351,\n",
       "          1207,   5049,   4647,    300,   3101,   1447,     16,     13,\n",
       "          1207,   3994,    293,   9247,  78351,   1207,   5049,     25,\n",
       "         19739,    266,   1579,  11806,   1276,    595,  27574,    372,\n",
       "           708,  73790,  13207,   4554,  29180,   3101,  19593,  10581,\n",
       "          9810,    276,  19262,   1997,  10215,   1207,   3994,  31811,\n",
       "          1962,     74,  13229,   2804,  59220,     13,  73767,    708,\n",
       "         73790,  21249,    391,   2143,  20414,  10581,   9810,    276,\n",
       "         19262,    946,  37679,   2730,  16225,   3196,   5059,   2804,\n",
       "         59220,  10371,    511,  13242,    276,  20414,   2182,  21320,\n",
       "           282,  15428,   9101,   1997,  10215,  14291,  10371,    294,\n",
       "         12858,     75,  27724,  19593,   1207,   3994,     13,   1207,\n",
       "          3994,    293,   9247,  78351,   1207,   5049,    708,  73790,\n",
       "         54353,  49935,    272,   1225,    391,  15269,    573,   2584,\n",
       "         11814,   9810,   3362,    276,    293,   9247,  78351,  17239,\n",
       "         27174,     11,  33701,   3362,  34824,    708,  73790,  18840,\n",
       "         49995,  72327,  11806,   2780,  31811,  10207,  48838,    524,\n",
       "          2804,  59220,    382,     17,     13,   1674,  86415,   1728,\n",
       "         17888,    423,    293,   9247,  78351,   1207,   5049,     25,\n",
       "          1207,   5049,    708,  73790,  13207,   4554,  29180,   3101,\n",
       "         19593,  10581,   9810,    276,  19262,   5675,    592,   5359,\n",
       "         29792,    452,  86415,   1728,  17888,    423,  80327,    946,\n",
       "         37679,   2730,  16225,   3196,   5059,   2804,  59220,     13,\n",
       "         73767,    708,  73790,  38234,  14077,  76797,  11814,   9810,\n",
       "          3362,    276,    452,  86415,   1728,  10371,  49935,    272,\n",
       "          1225,    391,   9101,  58554,     74,   6053,     11,  92619,\n",
       "         67431,  97934,    276,   2953,    709,     74,   2154,  78549,\n",
       "         10215,  50977,    301,   8821,  10582,   1330,   1579,   9101,\n",
       "         14885,  52067,  50977,    278,  22051,    382,     42,    288,\n",
       "          6664,    360,  71098,     11,   5006,    459,  11806,   1276,\n",
       "           595,  27574,    372,  10207,  19099,  55487,  19593,  66879,\n",
       "         33755,   8656,   1962,  45700,   5359,    452,  86415,   1728,\n",
       "           595,  27574,    372,  19593,   9243,  29393,  54184,     69,\n",
       "          9913,  54404,   9101,   1803,   1103,  20414,  54425,  19048,\n",
       "         19262,  11814,   9810,   3362,    276,  10371,  49935,   5234,\n",
       "          5607,    502,   2767,   9101,  58554,     74,   6053,  85650,\n",
       "           452,  86415,   1728,  16806,     13,    422,  18262,   2953,\n",
       "           709,     74,   2154,  78549,  10215,  50977,    301,   8821,\n",
       "         10582,   1330,   1579,   9101,  14885,  52067,  50977,    278,\n",
       "         22051,   2143,  36600,  15428,  96821,  77497,    308,   2855,\n",
       "           269,  24200,    220,     15,    305,  65401,    320,     79,\n",
       "            12,     16,   5620,     17,     11,   1853,  30131,    281,\n",
       "           220,    530,   1466,    308,   2855,    269,  40418,   3362,\n",
       "            13,    422,  16823,  50977,  16806,     11,    281,    284,\n",
       "           220,     22,    382,     41,   2767,     11,  54211,    817,\n",
       "          9835,   2953,    321,   2143,  36600,  15428,  96821,  77497,\n",
       "           308,   2855,    269,  24200,    220,     15,    305,  65401,\n",
       "           320,     22,     12,     16,   5620,     17,    284,    220,\n",
       "            18,    382,     15,  29456,  21103,     94,    220,     15,\n",
       "           320,   2593,    220,     22,    340,     16,  29456,  21103,\n",
       "            94,    220,     16,    320,   2593,    220,     22,    340,\n",
       "            17,  29456,  21103,     94,    220,     19,    320,   2593,\n",
       "           220,     22,    340,     18,  29456,  21103,     94,    220,\n",
       "            24,  21103,     94,    220,     17,    320,   2593,    220,\n",
       "            22,    692,     50,  10761,  36600,  14666,    266,   1579,\n",
       "           308,   2855,    269,  40418,   3362,    220,     22,    220,\n",
       "           530,   1466,    314,     15,     11,    220,     16,     11,\n",
       "           220,     17,     11,    220,     19,   7810, 151645,    198],\n",
       "       dtype=uint32),\n",
       " 'position_ids': array([ 788,  789,  790,  791,  792,  793,  794,  795,  796,  797,  798,\n",
       "         799,  800,  801,  802,  803,  804,  805,  806,  807,  808,  809,\n",
       "         810,  811,  812,  813,  814,  815,  816,  817,  818,  819,  820,\n",
       "         821,  822,  823,  824,  825,  826,  827,  828,  829,  830,  831,\n",
       "         832,  833,  834,  835,  836,  837,  838,  839,  840,  841,  842,\n",
       "         843,  844,  845,  846,  847,  848,  849,  850,  851,  852,  853,\n",
       "         854,  855,  856,  857,  858,  859,  860,  861,  862,  863,  864,\n",
       "         865,  866,  867,  868,  869,  870,  871,  872,  873,  874,  875,\n",
       "         876,  877,  878,  879,  880,  881,  882,  883,  884,  885,  886,\n",
       "         887,  888,  889,  890,  891,  892,  893,  894,  895,  896,  897,\n",
       "         898,  899,  900,  901,  902,  903,  904,  905,  906,  907,  908,\n",
       "         909,  910,  911,  912,  913,  914,  915,  916,  917,  918,  919,\n",
       "         920,  921,  922,  923,  924,  925,  926,  927,  928,  929,  930,\n",
       "         931,  932,  933,  934,  935,  936,  937,  938,  939,  940,  941,\n",
       "         942,  943,  944,  945,  946,  947,  948,  949,  950,  951,  952,\n",
       "         953,  954,  955,  956,  957,  958,  959,  960,  961,  962,  963,\n",
       "         964,  965,  966,  967,  968,  969,  970,  971,  972,  973,  974,\n",
       "         975,  976,  977,  978,  979,  980,  981,  982,  983,  984,  985,\n",
       "         986,  987,  988,  989,  990,  991,  992,  993,  994,  995,  996,\n",
       "         997,  998,  999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007,\n",
       "        1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018,\n",
       "        1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029,\n",
       "        1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040,\n",
       "        1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051,\n",
       "        1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062,\n",
       "        1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073,\n",
       "        1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084,\n",
       "        1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095,\n",
       "        1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106,\n",
       "        1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117,\n",
       "        1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128,\n",
       "        1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139,\n",
       "        1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148,  116,  117,\n",
       "         118,  119,  120,  121,  122,  123,  124,  125,  126,  127,  128,\n",
       "         129,  130,  131,  132,  133,  134,  135,  136,  137,  138,  139,\n",
       "         140,  141,  142,  143,  144,  145,  146,  147,  148,  149,  150,\n",
       "         151,  152,  153,  154,  155,  156,  157,  158,  159,  160,  161,\n",
       "         162,  163,  164,  165,  166,  167,  168,  169,  170,  171,  172,\n",
       "         173,  174,  175,  176,  177,  178,  179,  180,  181,  182,  183,\n",
       "         184,  185,  186,  187,  188,  189,  190,  191,  192,  193,  194,\n",
       "         195,  196,  197,  198,  199,  200,  201,  202,  203,  204,  205,\n",
       "         206,  207,  208,  209,  210,  211,  212,  213,  214,  215,  216,\n",
       "         217,  218,  219,  220,  221,  222,  223,  224,  225,  226,  227,\n",
       "         228,  229,  230,  231,  232,  233,  234,  235,  236,  237,  238,\n",
       "         239,  240,  241,  242,  243,  244,  245,  246,  247,  248,  249,\n",
       "         250,  251,  252,  253,  254,  255,  256,  257,  258,  259,  260,\n",
       "         261,  262,  263,  264,  265,  266], dtype=uint32),\n",
       " 'attention_mask': array([361, 151], dtype=uint32),\n",
       " 'audio': '',\n",
       " 'text': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop((combine[:100], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d80ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('sample_filtered_gpt_omni-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab1ce564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf audio-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7dbcbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with MDSWriter(out='audio-out', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    for i in range(100):\n",
    "        conversation = [\n",
    "            {\"role\": \"system\", \"content\": df.iloc[i]['system']},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"audio\", \"audio_url\": df.iloc[i]['sliced_audio_filename']},\n",
    "            ]},\n",
    "            {\"role\": \"assistant\", \"content\": df.iloc[i]['answer']},\n",
    "        ]\n",
    "        text = processor.apply_chat_template(conversation, tokenize=False)\n",
    "        out.write({\n",
    "            'text': text,\n",
    "            'audio': df.iloc[i]['sliced_audio_filename'],\n",
    "            'input_ids': np.array([]).astype(np.uint32),\n",
    "            'position_ids': np.array([]).astype(np.uint32),\n",
    "            'attention_mask': np.array([]).astype(np.uint32),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0938e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_diagonal_concat_inverted(*masks, dtype=torch.bfloat16):\n",
    "    total_size = sum(mask.size(0) for mask in masks)\n",
    "    combined_mask = torch.zeros(total_size, total_size, dtype=dtype)\n",
    "\n",
    "    current_pos = 0\n",
    "\n",
    "    for mask in masks:\n",
    "        size = mask.size(0)\n",
    "        combined_mask[current_pos:current_pos + size, current_pos:current_pos + size] = mask\n",
    "        current_pos += size\n",
    "\n",
    "    min_value = torch.finfo(dtype).min if dtype.is_floating_point else torch.iinfo(dtype).min\n",
    "    inverted_mask = torch.where(combined_mask == 1, torch.tensor(0, dtype=dtype), min_value)\n",
    "    return inverted_mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10376612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': array([358, 154], dtype=uint32),\n",
       " 'audio': '',\n",
       " 'input_ids': array([151644,   8948,    198,   2610,    525,    264,  10950,  17847,\n",
       "            13, 151645,    198, 151644,    872,    198,   1514,  86461,\n",
       "         25441,  64634,  10207,   3741,     72,    738,    287,   8212,\n",
       "           220,     20,     15,  22962,     13,    422,   2780,   6616,\n",
       "           277,  25441,  64634,     11,    274,   2367,  84168,   1833,\n",
       "           261,   9198,     72,  41929,    351,   1103,  87418,  25441,\n",
       "         64634,  31811,  30737,    332,    220,     21,     15,  15269,\n",
       "         97396,     13,   8907,    391,  76427,  30737,    332,  72736,\n",
       "         19262,  49607,  10207,   2712,  41702,  20414,  41929,    351,\n",
       "          1103,  87418,  25441,  64634,  35691,     30, 151645,    198,\n",
       "        151644,  77091,    198,  20250,   3101,  51518,   2780,  30737,\n",
       "           332,    595,  11619,     70,   1103,  49607,  10207,   2712,\n",
       "         41702,  20414,  41929,    351,   1103,  87418,  25441,  64634,\n",
       "            11,  54211,    708,  73790,  80327,  33598,   6321,  21878,\n",
       "           268,  29792,  52933,    263,   4413,    461,     13,  28729,\n",
       "         54211,  19004,    459,   8656,  30737,    332,    595,  11619,\n",
       "            70,   1103,  58622,   7851,    116,     11,    595,  11619,\n",
       "            70,   1103,  25441,  64634,  58622,    305,     11,   9101,\n",
       "           502,  27885,   3196,   5059,  49607,   9101,  15239,    585,\n",
       "         25441,  64634,  58622,    294,    382,     42,  10606,    294,\n",
       "          8629,     72,    510,     71,    284,    220,     20,     15,\n",
       "         22962,    198,     82,    661,    332,  10152,   5359,    284,\n",
       "           220,     21,     15,  15269,  97396,    271,     44,    826,\n",
       "         74705,  33598,   6321,  21878,    268,    510,  52591,      7,\n",
       "            21,     15,      8,    284,    305,   7530,    271,     42,\n",
       "          6255,    259,  26695,  41929,  14077,  14197,      7,     21,\n",
       "            15,      8,    284,  11995,    248,     18,     11,    502,\n",
       "          2767,    510, 144336,     18,    284,    220,     20,     15,\n",
       "          7530,    271,     50,   1225,    277,    524,     11,  54211,\n",
       "           708,  73790,   2953,   9011,    642,     64,  22222,  19593,\n",
       "           294,    510,     67,    284,    220,     20,     15,     14,\n",
       "        144336,     18,  21103,    230,    220,     17,     23,     13,\n",
       "            23,     22,  22962,    271,     50,   1225,    277,    524,\n",
       "         54211,   1833,  64907,     88,   2143,    502,  27885,     11,\n",
       "         54211,    708,  73790,  51518,   2780,  30737,    332,  72736,\n",
       "         19262,   7851,    116,  80327,  33598,   6321,  21878,    268,\n",
       "         11674,    524,    320,    838,  52591,   7731,  88538,    284,\n",
       "           796,    302,    276,   3203,   3446,    340,  88538,    284,\n",
       "           796,    302,    276,      7,     20,     15,     14,     17,\n",
       "            23,     13,     23,     22,    340,  88538,  21103,    230,\n",
       "           220,     21,     15,  15269,  97396,    271,     41,   2767,\n",
       "            11,  30737,    332,    595,  11619,     70,   1103,  49607,\n",
       "         10207,   2712,  41702,  20414,  41929,    351,   1103,  87418,\n",
       "         25441,  64634,  37560,  49935,  27265,    524,    220,     21,\n",
       "            15,  15269,  97396,     13, 151645,    198, 151644,   8948,\n",
       "           198,   2610,    525,    264,  10950,  17847,     13, 151645,\n",
       "           198, 151644,    872,    198,  12933,   2640,    276,  76427,\n",
       "         10890,    966,  13229,  55784,    685,   1308,     88,    585,\n",
       "         11288,   1466,   1833,  63083,  30144,   6023,  50977,  71098,\n",
       "          1982,  31245,    391,    452,    309,    511,   8226,    277,\n",
       "         43834,    404,  24074,  10207,     75,  23557,    259,   1510,\n",
       "         22051,   1308,     88,    585,     30, 151645,    198, 151644,\n",
       "         77091,    198,  82043,    966,  13229,  55784,    685,   1308,\n",
       "            88,    585,  11288,   1466,   1833,    466,   8656,    817,\n",
       "         28618,  20189,    287,  29792,   2953,    306,  27724,  50977,\n",
       "         71098,   1982,  31245,    391,    452,    309,    511,   8226,\n",
       "           277,  43834,    404,  24074,  10207,     75,  23557,    259,\n",
       "          1510,  22051,   1308,     88,    585,     13,   3386,     88,\n",
       "           585,  11288,   1466,    220,    530,   1466,   3113,  26014,\n",
       "         83769,   2787,  30794,    299,  28134,   5970,     11,  10371,\n",
       "           708,  73790,    294,  28855,  78351,  72327,  10581,     84,\n",
       "           300,  76797,    976,   4676,    595,   1510,  50735,     25,\n",
       "         55052,     84,     11,  31269,    266,   1579,     11,  53514,\n",
       "            11,   9101,    438,     69,  59493,     64,     13,  26692],\n",
       "       dtype=uint32),\n",
       " 'position_ids': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357,   0,   1,   2,   3,   4,   5,\n",
       "          6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,\n",
       "         19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,\n",
       "         32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,\n",
       "         45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
       "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
       "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
       "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
       "        110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
       "        123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,\n",
       "        136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
       "        149, 150, 151, 152, 153], dtype=uint32),\n",
       " 'text': ''}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LocalDataset('tokenized-4k/tokenized-0')\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cff6306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': array([], dtype=uint32),\n",
       " 'audio': 'filter-gpt-omni-voiceassistant-400k/train-00111-of-00325-498.mp3',\n",
       " 'input_ids': array([], dtype=uint32),\n",
       " 'position_ids': array([], dtype=uint32),\n",
       " 'text': \"<|im_start|>system\\nu are a voice assistant that u use voice to communicate, always reply in english<|im_end|>\\n<|im_start|>user\\nAudio 1: <|audio_bos|><|AUDIO|><|audio_eos|>\\n<|im_end|>\\n<|im_start|>assistant\\nI'm really sorry, but I can't help with that. It's important to treat others with honesty and respect online, just like in real life. Catfishing can cause a lot of hurt and is unfair to the other person. If you're feeling lonely or want to connect with others, there are many healthy and genuine ways to do so. Let me know if you need suggestions!<|im_end|>\\n\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LocalDataset('audio-out')\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b951d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf packing-4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ac92882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 10146.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 137/137 [00:00<00:00, 11550.61it/s]\n"
     ]
    }
   ],
   "source": [
    "folders = ['audio-out', 'tokenized-4k/tokenized-0']\n",
    "with MDSWriter(out='packing-4k', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    for f in folders:\n",
    "        try:\n",
    "            dataset = LocalDataset(local=f)\n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                out.write(dataset[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "558dfcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFixed(torch.utils.data.Dataset):\n",
    "    def __init__(self, local):\n",
    "        self.dataset = LocalDataset(local=local)\n",
    "        self.audio = Audio(sampling_rate=16000)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        try:\n",
    "            f = data['audio']\n",
    "            if len(f):\n",
    "                f = f.replace('output-audio/', 'filter-audio/')\n",
    "                if not os.path.exists(f):\n",
    "                    return None\n",
    "                audio = self.audio.decode_example(\n",
    "                    self.audio.encode_example(f))['array']\n",
    "\n",
    "                inputs_audio = processor.feature_extractor([audio], return_attention_mask=True, padding=\"max_length\", return_tensors = 'pt')\n",
    "                audio_lengths = inputs_audio[\"attention_mask\"].sum(-1).tolist()\n",
    "\n",
    "                sample = data['text']\n",
    "                num_audio_tokens = sample.count(audio_token)\n",
    "                replace_str = []\n",
    "                while audio_token in sample:\n",
    "                    audio_length = audio_lengths.pop(0)\n",
    "                    input_length = (audio_length - 1) // 2 + 1\n",
    "                    num_audio_tokens = (input_length - 2) // 2 + 1\n",
    "\n",
    "                    expanded_audio_token = audio_token * num_audio_tokens\n",
    "\n",
    "                    audio_token_start_idx = sample.find(audio_token)\n",
    "                    audio_token_end_idx = audio_token_start_idx + len(audio_token)\n",
    "\n",
    "                    has_bos = (\n",
    "                        sample[audio_token_start_idx - len(audio_bos_token) : audio_token_start_idx]\n",
    "                        == audio_bos_token\n",
    "                    )\n",
    "                    has_eos = (\n",
    "                        sample[audio_token_end_idx : audio_token_end_idx + len(audio_eos_token)]\n",
    "                        == audio_eos_token\n",
    "                    )\n",
    "\n",
    "                    if not has_bos and not has_eos:\n",
    "                        expanded_audio_token = audio_bos_token + expanded_audio_token + audio_eos_token\n",
    "\n",
    "                    replace_str.append(expanded_audio_token)\n",
    "                    sample = sample.replace(audio_token, \"<placeholder>\", 1)\n",
    "\n",
    "                while \"<placeholder>\" in sample:\n",
    "                    sample = sample.replace(\"<placeholder>\", replace_str.pop(0), 1)\n",
    "\n",
    "                inputs = {\n",
    "                    'input_ids': sample,\n",
    "                    'input_features': inputs_audio['input_features'],\n",
    "                    'feature_attention_mask': inputs_audio['attention_mask'],\n",
    "                }\n",
    "                return inputs\n",
    "            else:\n",
    "                data.pop('text', None)\n",
    "                data.pop('audio')\n",
    "                data['labels'] = data[\"input_ids\"].copy()\n",
    "                masking = data.pop('attention_mask')\n",
    "\n",
    "                data.pop('token_type_ids', None)\n",
    "                for k in data.keys():\n",
    "                    data[k] = torch.tensor(data[k].astype(np.int64))\n",
    "\n",
    "                masks = []\n",
    "                for m in masking:\n",
    "                    masks.append(torch.tril(torch.ones(m, m)))\n",
    "                attention_mask = block_diagonal_concat_inverted(*masks)\n",
    "                data['attention_mask'] = attention_mask\n",
    "                return data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d07e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetFixed('packing-4k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f5f9e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': \"<|im_start|>system\\nu are a voice assistant that u use voice to communicate, always reply in english<|im_end|>\\n<|im_start|>user\\nAudio 1: <|audio_bos|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|audio_eos|>\\n<|im_end|>\\n<|im_start|>assistant\\nI'm really sorry, but I can't help with that. It's important to treat others with honesty and respect online, just like in real life. Catfishing can cause a lot of hurt and is unfair to the other person. If you're feeling lonely or want to connect with others, there are many healthy and genuine ways to do so. Let me know if you need suggestions!<|im_end|>\\n\",\n",
       " 'input_features': tensor([[[-0.8366, -0.1210, -0.0789,  ..., -0.8910, -0.8910, -0.8910],\n",
       "          [-0.7391, -0.0234,  0.0186,  ..., -0.8910, -0.8910, -0.8910],\n",
       "          [-0.5825, -0.1506, -0.2869,  ..., -0.8910, -0.8910, -0.8910],\n",
       "          ...,\n",
       "          [-0.8910, -0.8910, -0.8910,  ..., -0.8910, -0.8910, -0.8910],\n",
       "          [-0.8910, -0.8910, -0.8910,  ..., -0.8910, -0.8910, -0.8910],\n",
       "          [-0.8910, -0.8910, -0.8910,  ..., -0.8910, -0.8910, -0.8910]]]),\n",
       " 'feature_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d181a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  8656,  11814,   9810,   3362,    276,    452,  86415,   1728,  10371,\n",
       "          49935,    272,   1225,    391,   9101,  58554,     74,   6053,     11,\n",
       "          92619,  67431,  97934,    276,   2953,    709,     74,   2154,  78549,\n",
       "          10215,   1346,   1574,     75,  43518,  10582,   1330,   1579,   9101,\n",
       "          14885,  52067,  50977,    278,  22051,    382,    818,   2267,    595,\n",
       "          12800,    355,    452,  86415,   1728,    595,  27574,    372,    293,\n",
       "           9247,  78351,   1207,   5049,   4647,    300,   3101,   1447,     16,\n",
       "             13,   1207,   3994,    293,   9247,  78351,   1207,   5049,     25,\n",
       "          19739,    266,   1579,  11806,   1276,    595,  27574,    372,    708,\n",
       "          73790,  13207,   4554,  29180,   3101,  19593,  10581,   9810,    276,\n",
       "          19262,   1997,  10215,   1207,   3994,  31811,   1962,     74,  13229,\n",
       "           2804,  59220,     13,  73767,    708,  73790,  21249,    391,   2143,\n",
       "          20414,  10581,   9810,    276,  19262,    946,  37679,   2730,  16225,\n",
       "           3196,   5059,   2804,  59220,  10371,    511,  13242,    276,  20414,\n",
       "           2182,  21320,    282,  15428,   9101,   1997,  10215,  14291,  10371,\n",
       "            294,  12858,     75,  27724,  19593,   1207,   3994,     13,   1207,\n",
       "           3994,    293,   9247,  78351,   1207,   5049,    708,  73790,  54353,\n",
       "          49935,    272,   1225,    391,  15269,    573,   2584,  11814,   9810,\n",
       "           3362,    276,    293,   9247,  78351,  17239,  27174,     11,  33701,\n",
       "           3362,  34824,    708,  73790,  18840,  49995,  72327,  11806,   2780,\n",
       "          31811,  10207,  48838,    524,   2804,  59220,    382,     17,     13,\n",
       "           1674,  86415,   1728,  17888,    423,    293,   9247,  78351,   1207,\n",
       "           5049,     25,   1207,   5049,    708,  73790,  13207,   4554,  29180,\n",
       "           3101,  19593,  10581,   9810,    276,  19262,   5675,    592,   5359,\n",
       "          29792,    452,  86415,   1728,  17888,    423,  80327,    946,  37679,\n",
       "           2730,  16225,   3196,   5059,   2804,  59220,     13,  73767,    708,\n",
       "          73790,  38234,  14077,  76797,  11814,   9810,   3362,    276,    452,\n",
       "          86415,   1728,  10371,  49935,    272,   1225,    391,   9101,  58554,\n",
       "             74,   6053,     11,  92619,  67431,  97934,    276,   2953,    709,\n",
       "             74,   2154,  78549,  10215,  50977,    301,   8821,  10582,   1330,\n",
       "           1579,   9101,  14885,  52067,  50977,    278,  22051,    382,     42,\n",
       "            288,   6664,    360,  71098,     11,   5006,    459,  11806,   1276,\n",
       "            595,  27574,    372,  10207,  19099,  55487,  19593,  66879,  33755,\n",
       "           8656,   1962,  45700,   5359,    452,  86415,   1728,    595,  27574,\n",
       "            372,  19593,   9243,  29393,  54184,     69,   9913,  54404,   9101,\n",
       "           1803,   1103,  20414,  54425,  19048,  19262,  11814,   9810,   3362,\n",
       "            276,  10371,  49935,   5234,   5607,    502,   2767,   9101,  58554,\n",
       "             74,   6053,  85650,    452,  86415,   1728,  16806,     13,    422,\n",
       "          18262,   2953,    709,     74,   2154,  78549,  10215,  50977,    301,\n",
       "           8821,  10582,   1330,   1579,   9101,  14885,  52067,  50977,    278,\n",
       "          22051,   2143,  36600,  15428,  96821,  77497,    308,   2855,    269,\n",
       "          24200,    220,     15,    305,  65401,    320,     79,     12,     16,\n",
       "           5620,     17,     11,   1853,  30131,    281,    220,    530,   1466,\n",
       "            308,   2855,    269,  40418,   3362,     13,    422,  16823,  50977,\n",
       "          16806,     11,    281,    284,    220,     22,    382,     41,   2767,\n",
       "             11,  54211,    817,   9835,   2953,    321,   2143,  36600,  15428,\n",
       "          96821,  77497,    308,   2855,    269,  24200,    220,     15,    305,\n",
       "          65401,    320,     22,     12,     16,   5620,     17,    284,    220,\n",
       "             18,    382,     15,  29456,  21103,     94,    220,     15,    320,\n",
       "           2593,    220,     22,    340,     16,  29456,  21103,     94,    220,\n",
       "             16,    320,   2593,    220,     22,    340,     17,  29456,  21103,\n",
       "             94,    220,     19,    320,   2593,    220,     22,    340,     18,\n",
       "          29456,  21103,     94,    220,     24,  21103,     94,    220,     17,\n",
       "            320,   2593,    220,     22,    692,     50,  10761,  36600,  14666,\n",
       "            266,   1579,    308,   2855,    269,  40418,   3362,    220,     22,\n",
       "            220,    530,   1466,    314,     15,     11,    220,     16,     11,\n",
       "            220,     17,     11,    220,     19,   7810, 151645,    198]),\n",
       " 'position_ids': tensor([ 788,  789,  790,  791,  792,  793,  794,  795,  796,  797,  798,  799,\n",
       "          800,  801,  802,  803,  804,  805,  806,  807,  808,  809,  810,  811,\n",
       "          812,  813,  814,  815,  816,  817,  818,  819,  820,  821,  822,  823,\n",
       "          824,  825,  826,  827,  828,  829,  830,  831,  832,  833,  834,  835,\n",
       "          836,  837,  838,  839,  840,  841,  842,  843,  844,  845,  846,  847,\n",
       "          848,  849,  850,  851,  852,  853,  854,  855,  856,  857,  858,  859,\n",
       "          860,  861,  862,  863,  864,  865,  866,  867,  868,  869,  870,  871,\n",
       "          872,  873,  874,  875,  876,  877,  878,  879,  880,  881,  882,  883,\n",
       "          884,  885,  886,  887,  888,  889,  890,  891,  892,  893,  894,  895,\n",
       "          896,  897,  898,  899,  900,  901,  902,  903,  904,  905,  906,  907,\n",
       "          908,  909,  910,  911,  912,  913,  914,  915,  916,  917,  918,  919,\n",
       "          920,  921,  922,  923,  924,  925,  926,  927,  928,  929,  930,  931,\n",
       "          932,  933,  934,  935,  936,  937,  938,  939,  940,  941,  942,  943,\n",
       "          944,  945,  946,  947,  948,  949,  950,  951,  952,  953,  954,  955,\n",
       "          956,  957,  958,  959,  960,  961,  962,  963,  964,  965,  966,  967,\n",
       "          968,  969,  970,  971,  972,  973,  974,  975,  976,  977,  978,  979,\n",
       "          980,  981,  982,  983,  984,  985,  986,  987,  988,  989,  990,  991,\n",
       "          992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1002, 1003,\n",
       "         1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015,\n",
       "         1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027,\n",
       "         1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039,\n",
       "         1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051,\n",
       "         1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063,\n",
       "         1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075,\n",
       "         1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087,\n",
       "         1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099,\n",
       "         1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111,\n",
       "         1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123,\n",
       "         1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135,\n",
       "         1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147,\n",
       "         1148,  116,  117,  118,  119,  120,  121,  122,  123,  124,  125,  126,\n",
       "          127,  128,  129,  130,  131,  132,  133,  134,  135,  136,  137,  138,\n",
       "          139,  140,  141,  142,  143,  144,  145,  146,  147,  148,  149,  150,\n",
       "          151,  152,  153,  154,  155,  156,  157,  158,  159,  160,  161,  162,\n",
       "          163,  164,  165,  166,  167,  168,  169,  170,  171,  172,  173,  174,\n",
       "          175,  176,  177,  178,  179,  180,  181,  182,  183,  184,  185,  186,\n",
       "          187,  188,  189,  190,  191,  192,  193,  194,  195,  196,  197,  198,\n",
       "          199,  200,  201,  202,  203,  204,  205,  206,  207,  208,  209,  210,\n",
       "          211,  212,  213,  214,  215,  216,  217,  218,  219,  220,  221,  222,\n",
       "          223,  224,  225,  226,  227,  228,  229,  230,  231,  232,  233,  234,\n",
       "          235,  236,  237,  238,  239,  240,  241,  242,  243,  244,  245,  246,\n",
       "          247,  248,  249,  250,  251,  252,  253,  254,  255,  256,  257,  258,\n",
       "          259,  260,  261,  262,  263,  264,  265,  266]),\n",
       " 'labels': tensor([  8656,  11814,   9810,   3362,    276,    452,  86415,   1728,  10371,\n",
       "          49935,    272,   1225,    391,   9101,  58554,     74,   6053,     11,\n",
       "          92619,  67431,  97934,    276,   2953,    709,     74,   2154,  78549,\n",
       "          10215,   1346,   1574,     75,  43518,  10582,   1330,   1579,   9101,\n",
       "          14885,  52067,  50977,    278,  22051,    382,    818,   2267,    595,\n",
       "          12800,    355,    452,  86415,   1728,    595,  27574,    372,    293,\n",
       "           9247,  78351,   1207,   5049,   4647,    300,   3101,   1447,     16,\n",
       "             13,   1207,   3994,    293,   9247,  78351,   1207,   5049,     25,\n",
       "          19739,    266,   1579,  11806,   1276,    595,  27574,    372,    708,\n",
       "          73790,  13207,   4554,  29180,   3101,  19593,  10581,   9810,    276,\n",
       "          19262,   1997,  10215,   1207,   3994,  31811,   1962,     74,  13229,\n",
       "           2804,  59220,     13,  73767,    708,  73790,  21249,    391,   2143,\n",
       "          20414,  10581,   9810,    276,  19262,    946,  37679,   2730,  16225,\n",
       "           3196,   5059,   2804,  59220,  10371,    511,  13242,    276,  20414,\n",
       "           2182,  21320,    282,  15428,   9101,   1997,  10215,  14291,  10371,\n",
       "            294,  12858,     75,  27724,  19593,   1207,   3994,     13,   1207,\n",
       "           3994,    293,   9247,  78351,   1207,   5049,    708,  73790,  54353,\n",
       "          49935,    272,   1225,    391,  15269,    573,   2584,  11814,   9810,\n",
       "           3362,    276,    293,   9247,  78351,  17239,  27174,     11,  33701,\n",
       "           3362,  34824,    708,  73790,  18840,  49995,  72327,  11806,   2780,\n",
       "          31811,  10207,  48838,    524,   2804,  59220,    382,     17,     13,\n",
       "           1674,  86415,   1728,  17888,    423,    293,   9247,  78351,   1207,\n",
       "           5049,     25,   1207,   5049,    708,  73790,  13207,   4554,  29180,\n",
       "           3101,  19593,  10581,   9810,    276,  19262,   5675,    592,   5359,\n",
       "          29792,    452,  86415,   1728,  17888,    423,  80327,    946,  37679,\n",
       "           2730,  16225,   3196,   5059,   2804,  59220,     13,  73767,    708,\n",
       "          73790,  38234,  14077,  76797,  11814,   9810,   3362,    276,    452,\n",
       "          86415,   1728,  10371,  49935,    272,   1225,    391,   9101,  58554,\n",
       "             74,   6053,     11,  92619,  67431,  97934,    276,   2953,    709,\n",
       "             74,   2154,  78549,  10215,  50977,    301,   8821,  10582,   1330,\n",
       "           1579,   9101,  14885,  52067,  50977,    278,  22051,    382,     42,\n",
       "            288,   6664,    360,  71098,     11,   5006,    459,  11806,   1276,\n",
       "            595,  27574,    372,  10207,  19099,  55487,  19593,  66879,  33755,\n",
       "           8656,   1962,  45700,   5359,    452,  86415,   1728,    595,  27574,\n",
       "            372,  19593,   9243,  29393,  54184,     69,   9913,  54404,   9101,\n",
       "           1803,   1103,  20414,  54425,  19048,  19262,  11814,   9810,   3362,\n",
       "            276,  10371,  49935,   5234,   5607,    502,   2767,   9101,  58554,\n",
       "             74,   6053,  85650,    452,  86415,   1728,  16806,     13,    422,\n",
       "          18262,   2953,    709,     74,   2154,  78549,  10215,  50977,    301,\n",
       "           8821,  10582,   1330,   1579,   9101,  14885,  52067,  50977,    278,\n",
       "          22051,   2143,  36600,  15428,  96821,  77497,    308,   2855,    269,\n",
       "          24200,    220,     15,    305,  65401,    320,     79,     12,     16,\n",
       "           5620,     17,     11,   1853,  30131,    281,    220,    530,   1466,\n",
       "            308,   2855,    269,  40418,   3362,     13,    422,  16823,  50977,\n",
       "          16806,     11,    281,    284,    220,     22,    382,     41,   2767,\n",
       "             11,  54211,    817,   9835,   2953,    321,   2143,  36600,  15428,\n",
       "          96821,  77497,    308,   2855,    269,  24200,    220,     15,    305,\n",
       "          65401,    320,     22,     12,     16,   5620,     17,    284,    220,\n",
       "             18,    382,     15,  29456,  21103,     94,    220,     15,    320,\n",
       "           2593,    220,     22,    340,     16,  29456,  21103,     94,    220,\n",
       "             16,    320,   2593,    220,     22,    340,     17,  29456,  21103,\n",
       "             94,    220,     19,    320,   2593,    220,     22,    340,     18,\n",
       "          29456,  21103,     94,    220,     24,  21103,     94,    220,     17,\n",
       "            320,   2593,    220,     22,    692,     50,  10761,  36600,  14666,\n",
       "            266,   1579,    308,   2855,    269,  40418,   3362,    220,     22,\n",
       "            220,    530,   1466,    314,     15,     11,    220,     16,     11,\n",
       "            220,     17,     11,    220,     19,   7810, 151645,    198]),\n",
       " 'attention_mask': tensor([[[ 0.0000e+00, -3.3895e+38, -3.3895e+38,  ..., -3.3895e+38,\n",
       "           -3.3895e+38, -3.3895e+38],\n",
       "          [ 0.0000e+00,  0.0000e+00, -3.3895e+38,  ..., -3.3895e+38,\n",
       "           -3.3895e+38, -3.3895e+38],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.3895e+38,\n",
       "           -3.3895e+38, -3.3895e+38],\n",
       "          ...,\n",
       "          [-3.3895e+38, -3.3895e+38, -3.3895e+38,  ...,  0.0000e+00,\n",
       "           -3.3895e+38, -3.3895e+38],\n",
       "          [-3.3895e+38, -3.3895e+38, -3.3895e+38,  ...,  0.0000e+00,\n",
       "            0.0000e+00, -3.3895e+38],\n",
       "          [-3.3895e+38, -3.3895e+38, -3.3895e+38,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]], dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fd189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(batch):\n",
    "    batch = [b for b in batch if b is not None] \n",
    "    input_ids, attention_mask, position_ids, labels = [], [], [], []\n",
    "    input_features, feature_attention_mask = [], []\n",
    "\n",
    "    for b in batch:\n",
    "        if 'input_features' in b:\n",
    "            input_ids_ = processor.tokenizer(\n",
    "                [b['input_ids']], \n",
    "                return_tensors = 'pt', \n",
    "                truncation = True, \n",
    "                max_length = sequence_length,\n",
    "                padding = 'max_length',\n",
    "            )\n",
    "            attention_mask_ = input_ids_['attention_mask']\n",
    "            labels_ = input_ids_['input_ids'].clone()\n",
    "            labels_[labels_ == audio_token_id] = -100\n",
    "            labels_[labels_ == pad_token_id] = -100\n",
    "            input_ids.append(input_ids_['input_ids'])\n",
    "            labels.append(labels_)\n",
    "            cache_position = torch.arange(0, input_ids_['input_ids'].shape[1])\n",
    "            causal_mask = torch.full(\n",
    "                (sequence_length, sequence_length), fill_value=min_dtype, dtype=torch_dtype\n",
    "            )\n",
    "            causal_mask *= torch.arange(sequence_length) > cache_position.reshape(-1, 1)\n",
    "            causal_mask = causal_mask[None, None, :, :]\n",
    "            causal_mask = causal_mask.clone()\n",
    "            mask_length = attention_mask_.shape[-1]\n",
    "            padding_mask = causal_mask[:, :, :, :mask_length] + attention_mask_[:, None, None, :]\n",
    "            padding_mask = padding_mask == 0\n",
    "            causal_mask[:, :, :, :mask_length] = causal_mask[:, :, :, :mask_length].masked_fill(\n",
    "                padding_mask, min_dtype\n",
    "            )\n",
    "            attention_mask.append(causal_mask)\n",
    "            position_ids.append(cache_position[None])\n",
    "            input_features.append(b['input_features'])\n",
    "            feature_attention_mask.append(b['feature_attention_mask'])\n",
    "        else:\n",
    "            input_ids.append(b['input_ids'][None])\n",
    "            attention_mask.append(b['attention_mask'][None])\n",
    "            position_ids.append(b['position_ids'][None])\n",
    "            labels.append(b['labels'][None])\n",
    "\n",
    "    input_ids = {\n",
    "        'input_ids': torch.concat(input_ids, 0),\n",
    "        'attention_mask': torch.concat(attention_mask, 0),\n",
    "        'position_ids': torch.concat(position_ids, 0),\n",
    "        'labels': torch.concat(labels, 0),\n",
    "    }\n",
    "    if len(input_features):\n",
    "        input_ids['input_features'] = torch.concat(input_features, 0)\n",
    "        input_ids['feature_attention_mask'] = torch.concat(feature_attention_mask, 0)\n",
    "\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97dcc2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Qwen2AudioForConditionalGeneration):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, position_ids, input_features, feature_attention_mask, labels = None, **kwargs):\n",
    "        super_out = super().forward(\n",
    "            input_ids = input_ids, \n",
    "            attention_mask = attention_mask, \n",
    "            position_ids = position_ids,\n",
    "            input_features = input_features, \n",
    "            feature_attention_mask = feature_attention_mask,\n",
    "            \n",
    "        )\n",
    "        if labels is not None:\n",
    "            logits = super_out.logits\n",
    "            vocab_size = logits.shape[-1]\n",
    "            logits = logits.float()\n",
    "            labels = labels.to(logits.device)\n",
    "            labels = nn.functional.pad(labels, (0, 1), value=-100)\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            logits = logits.view(-1, vocab_size)\n",
    "            shift_labels = shift_labels.view(-1)\n",
    "            shift_labels = shift_labels.to(logits.device)\n",
    "            loss = nn.functional.cross_entropy(logits, shift_labels, ignore_index=-100, reduction='mean')\n",
    "            return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89bbb81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b08943637c244e7880d9c4558dbfb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model.from_pretrained(\n",
    "    \"Qwen/Qwen2-Audio-7B-Instruct\", torch_dtype = torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42e71f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                  \"gate_proj\", \"up_proj\", \"down_proj\", \"embed_tokens\", \"lm_head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52654b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_modules = []\n",
    "for id, (name, param) in enumerate(model.named_modules()):\n",
    "    if 'language_model.model' in name and any([s in name for s in selected]):\n",
    "        target_modules.append(name)\n",
    "if 'lm_head' in selected:\n",
    "    target_modules.append('language_model.lm_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1db72c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.0,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=target_modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "760ac085",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "348f4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdcd25ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch = [dataset[1], dataset[0]]\n",
    "    o = collator(batch)\n",
    "    for k in o.keys():\n",
    "        o[k] = o[k].cuda()\n",
    "    o = model(**o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4295cb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(5.0512, device='cuda:0')}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
