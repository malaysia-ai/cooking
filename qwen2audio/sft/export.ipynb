{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40bbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/home/husein/ssd3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f6c6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, Qwen2AudioForConditionalGeneration, AutoConfig, AutoModelForCausalLM\n",
    "from transformers import TextStreamer\n",
    "from datasets import Audio\n",
    "import torch\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ea71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_class = Audio(sampling_rate=16000)\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "tokenizer = processor.tokenizer\n",
    "audio_token = \"<|AUDIO|>\"\n",
    "audio_bos_token = \"<|audio_bos|>\"\n",
    "audio_eos_token = \"<|audio_eos|>\"\n",
    "audio_token_id = processor.tokenizer._convert_token_to_id_with_added_voc('<|AUDIO|>')\n",
    "pad_token_id = processor.tokenizer.pad_token_id\n",
    "torch_dtype = torch.bfloat16\n",
    "min_dtype = torch.finfo(torch_dtype).min\n",
    "sequence_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3cf87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "886daaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/malayloraenjoyer/Malaysian-Qwen2-Audio-7B-Instruct-128/resolve/main/checkpoint-800/adapter_model.safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4d48b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0043c7bb8246a882b675e9a1af0307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ori_model = Qwen2AudioForConditionalGeneration.from_pretrained(\n",
    "    'Qwen/Qwen2-Audio-7B-Instruct', torch_dtype = torch.bfloat16,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0551bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = ori_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b77fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "f = safe_open(f\"adapter_model.safetensors\", framework=\"pt\", device=0)\n",
    "keys = f.keys()\n",
    "keys = sorted(list(set([k.split('.lora')[0] for k in keys if '.lora' in k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ade25ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:01<00:00, 204.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for k in tqdm(keys):\n",
    "    k_ori = k.replace('base_model.model.', '') + '.weight'\n",
    "    if 'embed_tokens' in k:\n",
    "        post_A = '.lora_embedding_A'\n",
    "        post_B = '.lora_embedding_B'\n",
    "    else:\n",
    "        post_A = '.lora_A.weight'\n",
    "        post_B = '.lora_B.weight'\n",
    "    A = k + post_A\n",
    "    B = k + post_B\n",
    "    \n",
    "    W = state_dict[k_ori]\n",
    "    if 'embed_tokens' not in k:\n",
    "        W = W.t()\n",
    "        \n",
    "    A = f.get_tensor(A).type(W.dtype)\n",
    "    B = f.get_tensor(B).type(W.dtype)\n",
    "    with torch.no_grad():\n",
    "        W.addmm_(A.t(), B.t(), alpha = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2536f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Audio 1: <|audio_bos|><|AUDIO|><|audio_eos|>\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Untuk mengkod website dengan React, anda perlu mempunyai beberapa konsep asas dan keupayaan pembangunan web. Berikut adalah langkah-langkah umum untuk mengkodkan sebuah website menggunakan React:\n",
      "\n",
      "1. **Pengenalan**:\n",
      "   - Kenal pasti keperluan dan tujuan projek anda. Contohnya, mungkin anda ingin membuat aplikasi berpusat atau aplikasi berprestasi tinggi.\n",
      "\n",
      "2. **Pemilihan teknologi**:\n",
      "   - Pilih bahasa pengaturcaraan yang sesuai seperti JavaScript, JSX\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"audio\", \"audio_url\": \"code-website-react.mp3\"},\n",
    "    ]},\n",
    "]\n",
    "text = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\n",
    "audios = []\n",
    "for message in conversation:\n",
    "    if isinstance(message[\"content\"], list):\n",
    "        for ele in message[\"content\"]:\n",
    "            if ele[\"type\"] == \"audio\":\n",
    "                audios.append(librosa.load(ele['audio_url'], \n",
    "                    sr=processor.feature_extractor.sampling_rate)[0]\n",
    "                )\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = processor(text=text, audios=audios, return_tensors=\"pt\", padding=True).to('cuda')\n",
    "    generate_kwargs = dict(\n",
    "        max_new_tokens=128,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.05,\n",
    "        streamer=streamer,\n",
    "        **inputs,\n",
    "    )\n",
    "    generation_output = ori_model.generate(**generate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67527745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Audio 1: <|audio_bos|><|AUDIO|><|audio_eos|>\n",
      "transcribe it in whisper word timestamps<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<|startoftranscript|><|ms|><|transcribe|><|0.14|> Yes, what can I help you here?<|1.66|><|2.06|> Do you want me to<|3.12|><|3.38|> open Gmail<|3.70|><|3.82|> and Facebook<|4.34|><|4.70|> ya?<|3.98|><|4.72|> Apa yang saya boleh tolong encheuk<|6.44|><|6.82|> nak sahaja buka akaun Gmail dan Facebook?<|8.86|><|7.74|> Ya?<|9.16|><|9.78|> Ya.<|9.84|><|9.90|> No, saya buka akaun<|4.56|><|4.74|> Gmail<|5.78|><|5.84|> dan Facebook<|6.00|><|6.76|> ya.<|7.78|><|7.88|> Ya?<|7.76|><|7.96|> Ya.<|9.88|><|10.08|> Ya.<|9.82|><|10.32|> Kalau tak,<|10.10|><|10.20|> saya buka punya<|10.08|><|10.40|>\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"audio\", \"audio_url\": \"speech.mp3\"},\n",
    "        {\"type\": \"text\", \"text\": \"transcribe it in whisper word timestamps\"},\n",
    "    ]},\n",
    "]\n",
    "text = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\n",
    "audios = []\n",
    "for message in conversation:\n",
    "    if isinstance(message[\"content\"], list):\n",
    "        for ele in message[\"content\"]:\n",
    "            if ele[\"type\"] == \"audio\":\n",
    "                audios.append(librosa.load(ele['audio_url'], \n",
    "                    sr=processor.feature_extractor.sampling_rate)[0]\n",
    "                )\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = processor(text=text, audios=audios, return_tensors=\"pt\", padding=True).to('cuda')\n",
    "    generate_kwargs = dict(\n",
    "        max_new_tokens=128,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.05,\n",
    "        streamer=streamer,\n",
    "        **inputs,\n",
    "    )\n",
    "    generation_output = ori_model.generate(**generate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d28b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
