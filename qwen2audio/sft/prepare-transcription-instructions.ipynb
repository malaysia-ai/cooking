{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e48999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import mp\n",
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6b62720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be42a424d7bf4d23be9568b9db30a03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd4c544b5ce4ac7bf9b62fd6eeff0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/638k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f791ccc2e3e04fecb4b9a971c418698d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb85ab3928c4c0d8a125b30a4d057dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f610583983c443c87fe7a0712b4cc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "tokenizer = processor.tokenizer\n",
    "audio_token = \"<|AUDIO|>\"\n",
    "audio_bos_token = \"<|audio_bos|>\"\n",
    "audio_eos_token = \"<|audio_eos|>\"\n",
    "audio_token_id = processor.tokenizer._convert_token_to_id_with_added_voc('<|AUDIO|>')\n",
    "pad_token_id = processor.tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d2fe4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_word = [\n",
    "    'transcribe the audio into Whisper format in word timestamp',\n",
    "    'audio to Whisper ASR format word timestamp',\n",
    "    'transkrip audio ke format word timestamp whisper',\n",
    "]\n",
    "templates_segment = [\n",
    "    'transcribe the audio into Whisper format in segment timestamp',\n",
    "    'audio to Whisper ASR format segment timestamp',\n",
    "    'transkrip audio ke format segment timestamp whisper',\n",
    "]\n",
    "templates_empty = [\n",
    "    'transcribe the audio',\n",
    "    'transkrip audio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efeaafec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04651c347ed8440db12120e633e2649a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/husein/ssd3/cooking/qwen2audio/sft'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot_download(\n",
    "    repo_id='malaysia-AI/STT-Whisper', \n",
    "    repo_type='dataset', allow_patterns = 'data/*.parquet', local_dir = './', max_workers = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a6f4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/tatabahasa_word-00000-of-00001.parquet',\n",
       " 'data/dialects_word-00000-of-00001.parquet',\n",
       " 'data/mallm_segment-00000-of-00001.parquet',\n",
       " 'data/tatabahasa_segment-00000-of-00001.parquet',\n",
       " 'data/malaysian_speech_instructions_segment_timestamp-00000-of-00001.parquet',\n",
       " 'data/mallm_word-00000-of-00001.parquet',\n",
       " 'data/dialects_segment-00000-of-00001.parquet',\n",
       " 'data/malaysian_speech_instructions_word_timestamp-00000-of-00001.parquet']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('data/*.parquet')\n",
    "files = [f for f in files if 'synthetic' not in f]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "963b8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(files):\n",
    "    files, _ = files\n",
    "    \n",
    "    data = []\n",
    "    for f in files:\n",
    "        template = templates_word if 'word' in f else templates_segment\n",
    "        template = random.choice(template)\n",
    "        rows = pd.read_parquet(f).to_dict(orient = 'records')\n",
    "        rows = random.sample(rows, min(len(rows), 100000))\n",
    "        for r in tqdm(rows):\n",
    "            conversation = [\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"audio\", \"audio_url\": r['audio_filename']},\n",
    "                    {\"type\": \"text\", \"text\": template},\n",
    "                ]},\n",
    "                {\"role\": \"assistant\", \"content\": r['new_text']},\n",
    "            ]\n",
    "            text = processor.apply_chat_template(conversation, tokenize=False)\n",
    "            f = r['audio_filename']\n",
    "            if 'dialects_processed' in f:\n",
    "                f = os.path.join('/home/husein/ssd3', f)\n",
    "            else:\n",
    "                f = os.path.join('/home/husein/ssd3/dataset/speech-instructions', f)\n",
    "                \n",
    "            data.append({\n",
    "                'text': text,\n",
    "                'audio': f,\n",
    "            })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72025967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 671/671 [00:00<00:00, 3780.96it/s]\n",
      " 61%|█████████████████████████████████████████████████▍                               | 1477/2422 [00:00<00:00, 7473.96it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 2422/2422 [00:00<00:00, 7602.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 2422/2422 [00:00<00:00, 7119.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:11<00:00, 8947.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:11<00:00, 8996.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:11<00:00, 8933.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:11<00:00, 8820.52it/s]\n"
     ]
    }
   ],
   "source": [
    "data = mp.multiprocessing(files, loop, cores = len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01f261df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406186"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd75b31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nAudio 1: <|audio_bos|><|AUDIO|><|audio_eos|>\\ntranscribe the audio into Whisper format in word timestamp<|im_end|>\\n<|im_start|>assistant\\n<|startoftranscript|><|ms|><|transcribeprecise|><|0.16|> Uh,<|0.18|><|0.32|> and<|0.42|><|0.48|> which<|0.62|><|0.68|> is<|0.76|><|0.88|> why<|1.18|><|1.60|> we,<|1.68|><|2.30|> we,<|2.38|><|2.66|> and<|2.74|><|2.82|> we've<|2.96|><|3.04|> done<|3.16|><|3.20|> this<|3.32|><|3.36|> to<|3.40|><|3.50|> ourselves.<|4.08|><|4.18|> We've,<|4.44|><|4.68|> you<|4.72|><|4.76|> know,<|4.82|><|5.16|> highly<|5.46|><|5.56|> recommend<|5.96|><|6.00|> putting<|6.22|><|6.28|> a<|6.28|><|6.36|> governance<|6.82|><|7.00|> mechanism<|7.48|><|7.56|> in<|7.58|><|7.68|> process<|8.20|><|8.74|> when<|8.82|><|8.88|> you're<|9.00|><|9.04|> deploying<|9.46|><|9.52|> general<|9.82|><|9.98|> AI<|10.04|><|10.12|> solutions<|10.54|><|10.60|> to<|10.64|><|10.74|> manage<|11.02|><|11.06|> the<|11.12|><|11.20|> risk<|11.44|><|11.64|> and<|11.76|><|11.80|> the<|11.86|><|12.10|> ROI.<|12.56|><|endoftext|><|im_end|>\\n\",\n",
       " 'audio': '/home/husein/ssd3/dialects_processed/Accelerate the value of generative AI with three secret ingredients [lfHiFaxln8A]/Accelerate the value of generative AI with three secret ingredients [lfHiFaxln8A]_58.mp3'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4c43b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prepare-transcription-instructions.json', 'w') as fopen:\n",
    "    json.dump(data, fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
